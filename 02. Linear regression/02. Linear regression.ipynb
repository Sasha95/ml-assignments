{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Линейная регрессия\n",
    "\n",
    "**Цель работы**: Изучить основные понятия машинного обучения, исследовать методы решения задачи регрессии, применить полученные знания для решения практических задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия\n",
    "\n",
    "### Обучающая выборка\n",
    "\n",
    "Задача регрессии заключается в поиске зависимости некоторой переменной $y$ от другой переменной $x$. При этом переменная $x$ может быть векторной.\n",
    "\n",
    "$$x=(x_1, x_2, \\dots, x_n).$$\n",
    "\n",
    "В этом случае говорят о *множественной регрессии*. В противном случае, если $x$ — скаляр, регрессию называют *парной*.\n",
    "\n",
    "Компоненты $x_j$ называются *признаками*.\n",
    "\n",
    "Набор данных, который используется для восстановления зависимости называется *обучающей выборкой*. Она представляет собой пару $(X, Y)$, где\n",
    "\n",
    "$$X = \n",
    "\\left(\n",
    "\\begin{array}%\n",
    "x^{(1)}\\\\\n",
    "x^{(2)}\\\\\n",
    "\\vdots\\\\\n",
    "x^{(m)}\\\\\n",
    "\\end{array}\n",
    "\\right) = \n",
    "\\left(\n",
    "\\begin{array}%\n",
    "x^{(1)}_1&x^{(1)}_2&\\dots&x^{(1)}_n\\\\\n",
    "x^{(2)}_1&x^{(2)}_2&\\dots&x^{(2)}_n\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\\\n",
    "x^{(m)}_1&x^{(m)}_2&\\dots&x^{(m)}_n\\\\\n",
    "\\end{array}\n",
    "\\right),\n",
    "Y = \n",
    "\\left(\n",
    "\\begin{array}%\n",
    "y^{(1)}\\\\\n",
    "y^{(2)}\\\\\n",
    "\\vdots\\\\\n",
    "y^{(m)}\\\\\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "Пара $(x^{(i)}, y^{(i)})$ называется *прецедентом*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Линейная регрессия\n",
    "\n",
    "Простейший случай регрессии — линейная регрессия. В ней искомая зависимость описывается линейной функцией.\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n = \\theta_0 + \\sum_{j=1}^n\\theta_jx_j.$$\n",
    "\n",
    "Здесь $h_{\\theta}(x)$ — обучаемая (в данном случае линейная) модель описывающая зависимость $y$ от $x$. Параметры $\\theta_j$ — параметры модели, а $\\theta$ — вектор параметров.\n",
    "\n",
    "$$\\theta = \\left(\n",
    "\\begin{array}%\n",
    "\\theta_0\\\\\n",
    "\\theta_1\\\\\n",
    "\\theta_2\\\\\n",
    "\\vdots\\\\\n",
    "\\theta_n\\\\\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "Для упрощения записи выражений можно ввести фиктивный признак \n",
    "\n",
    "$$x_0 \\equiv 1.$$\n",
    "\n",
    "Этот признак добавляется к исходным данным как столбец из 1 в матрице $X$.\n",
    "\n",
    "Тогда модель записывается как скалярное произведение\n",
    "\n",
    "$$h_{\\theta}(x) = \\sum_{j=1}^m x_j \\theta_j = x \\theta.$$\n",
    "\n",
    "Значения, предсказанные моделью для каждого набора признаком из обучающей выборки можно вычислить аналогично.\n",
    "\n",
    "$$h_{\\theta}(X) = X \\theta.$$\n",
    "\n",
    "В этом случае получаем вектор-столбец со значениями $h_{\\theta}(x^{(i)})$ для всех $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Функция потерь\n",
    "\n",
    "Параметры $\\theta$ выбираются таким образом, чтобы минимизировать ошибку между предсказанными ($h_{\\theta}(X)$) и известными в обучающей выборке ($Y$) значениями.\n",
    "\n",
    "Часто в качестве меры такой ошибки берут среднеквадратическое отклонение.\n",
    "\n",
    "$$J(\\theta) = \\frac1{2m}\\sum_{i=1}^{m}\\left[h_{\\theta}(x^{(i)})-y^{(i)}\\right]^2$$\n",
    "\n",
    "Функция $J(\\theta)$ называется *функцией потерь*.\n",
    "\n",
    "Тогда параметры модели находят как аргумент минимума функции потерь\n",
    "\n",
    "$$\\theta = \\arg\\min_{\\theta}J(\\theta).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "В настоящей лабораторной работе требуется решить задачу поиска оптимального ветора $\\theta$ с помощью следующих методов:\n",
    "\n",
    "- нормальное уравнение,\n",
    "- метод градиентного спуска,\n",
    "- метод BFGS (алгоритм реализован в библиотеке SciPy).\n",
    "\n",
    "Дополнительное задание: попробуйте нормировать исходные данные. Не забудьте сохранить параметры, с которыми выполнялась нормализация (среднее значение и разброс)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as so\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('font', family='Verdana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1. Зависимость роста от возраста\n",
    "\n",
    "Требуется найти зависимость роста (в метрах) от возраста (в годах) детей.\n",
    "\n",
    "Загрузим обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat('heights.mat')\n",
    "Xdata = data['age']\n",
    "ydata = data['height']\n",
    "\n",
    "# Xp, Yp задают линию, которая будет отображена на графике поверх данных\n",
    "def plot_data(X, y, Xp=None, yp=None):\n",
    "    plt.plot(X, y, 'xr')\n",
    "    if Xp is not None and yp is not None:\n",
    "        plt.plot(Xp, yp, '-b')\n",
    "    plt.xlabel('Возраст, лет')\n",
    "    plt.ylabel('Рост, м')\n",
    "    plt.title('Зависимость роста от возраста')\n",
    "    plt.show()\n",
    "\n",
    "plot_data(Xdata, ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введём вспомогательные величины: $m$ — число прецедентов, $n$ — номер последнего признака. (В функциях ими пользоваться нежелательно, так как функции должны быть как можно более изолированы от остального кода.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, n = Xdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к матрице $X$ слева столбец из единиц с помощью функции `np.concatenate`. Не забудьте в дальнейшем при расчётах использовать матрицу `X1` вместо `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xdata1 = np.concatenate([np.ones((m,1)), Xdata], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите выражение для модели $h_{\\theta}(x)$.\n",
    "\n",
    "$x$ может быть как вектор-строкой размера $1\\times (n+1)$, так и матрицей (то есть набором вектор-строк).\n",
    "\n",
    "$\\theta$ — вектор-столбец размера $(n+1)\\times 1$.\n",
    "\n",
    "Функция должна возвращать предсказанное значение для каждой строки параметра `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    # Проверки входных данных\n",
    "    assert len(X.shape) == 2, \"X — матрица?\"\n",
    "    assert X.shape[1] == n+1, \"Неверный размер матрицы X. Забыли столбец из 1?\" \n",
    "    assert theta.shape == (n+1, 1), \"Неверный размер матрицы theta\"\n",
    "    \n",
    "    # ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "    return np.ones((X.shape[0], 1))\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу функции для прямой пропорциональности. Параметры $\\theta$ выбраны произвольно и не соответствуют искомому решению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = np.array([[1], [0.1]])\n",
    "yp = h(Xdata1, theta) # Предсказанные значения\n",
    "plot_data(Xdata, ydata, Xdata, yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормальное уравнение\n",
    "Найдём $\\theta$ с помощью нормального уравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "theta_norm = np.array([[0], [1]])\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графически оценим результаты вычислений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (theta_norm)\n",
    "yp = h(Xdata1, theta_norm) # Предсказанные значения\n",
    "plot_data(Xdata, ydata, Xdata, yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Найдём $\\theta$ методом градиентного спуска. Для этого определим функции `J` и `dJ`, соответствующие функции потерь и вектору градиента.\n",
    "\n",
    "Функция `J` принимает на входе как вектор-столбец параметров `theta`, так и данные обучающей выборки — `X` и `y`. Функция должна вернуть число, характеризующее среднюю ошибку предсказанного моделью значения от истинного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def J(theta, X, y):\n",
    "    # Проверки входных данных\n",
    "    assert len(X.shape) == 2, \"X — матрица?\"\n",
    "    assert X.shape[1] == n+1, \"Неверный размер матрицы X. Забыли столбец из 1?\" \n",
    "    assert X.shape[0] == y.shape[0], \"Разное количество выходных и входных переменных\"\n",
    "    assert theta.shape == (n+1, 1), \"Неверный размер матрицы theta\"\n",
    "    \n",
    "    # ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "    return 0.0\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры функции, вычисляющей градиент, те же, но она должна вернуть вектор-столбец со значениями производной $\\frac{\\partial J(\\theta)}{\\partial\\theta_j}$ по каждому из параметров $\\theta_j$. Этот вектор-столбец, очевидно, должен иметь те же размеры, что и вектор $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dJ(theta, X, y):\n",
    "    # Проверки входных данных\n",
    "    assert len(X.shape) == 2, \"X — матрица?\"\n",
    "    assert X.shape[1] == n+1, \"Неверный размер матрицы X. Забыли столбец из 1?\" \n",
    "    assert X.shape[0] == y.shape[0], \"Разное количество выходных и входных переменных\"\n",
    "    assert theta.shape == (n+1, 1), \"Неверный размер матрицы theta\"\n",
    "    \n",
    "    # ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "    return np.zeros(theta.shape)\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам градиентный спуск выполняется достаточно просто: выполняются шаги в сторону, противоположную направлению градиента, пока его норма не станет достаточно малой (то есть, не станет меньше некоторого $\\varepsilon$). Конечно, за простоту приходится платить — более совершенные методы точнее и быстрее сходятся.\n",
    "\n",
    "Для работы метода необходимо правильно подобрать параметры $\\varepsilon$ (параметр, управляющей точностью) и $\\alpha$ (коэффициент шага градиентного спуска)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "# НАЙДИТЕ ОПТИМАЛЬНОЕ ЗНАЧЕНИЕ КОЭФФИЦИЕНТА alpha\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Основной алгоритм выглядит следующим образом.\n",
    "\n",
    "В массиве `norms` накапливаются значения нормы на каждом шаге цикла. Они нужны для точной «подстройки» парметра $\\alpha$.\n",
    "\n",
    "Если число итераций превышает `Kmax`, алгоритм завершается принудительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k, Kmax = 0, 10000\n",
    "norms = []\n",
    "\n",
    "# Инициализация\n",
    "theta_grad = np.zeros((n+1, 1))\n",
    "while True:\n",
    "    d = dJ(theta_grad, Xdata1, ydata) # Текущее значение градиента\n",
    "    \n",
    "    norm = np.linalg.norm(d)\n",
    "    norms.append(norm)\n",
    "    k += 1\n",
    "    if k > Kmax or norm < eps: break\n",
    "\n",
    "    # Один шаг градиентного спуска\n",
    "    # ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "    theta_grad = np.zeros((n+1, 1))\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график изменений нормы градиента в зависимости от номера итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(norms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Графически оценим результаты вычислений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (theta_grad)\n",
    "yp = h(Xdata1, theta_grad) # Предсказанные значения\n",
    "plot_data(Xdata, ydata, Xdata, yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Бройдена — Флетчера — Гольдфарба — Шанно (BFGS)\n",
    "\n",
    "Этот метод реализован в функции `sp.optimize.minimize`. Воспользуйтесь ей, чтобы найти оптимальное значение вектора $\\theta$. (Учтите, что команда находит минимум функции от нескольких переменных. Параметр `theta` нужно будет распаковать, а параметры `X` и `y` связать замыканием.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "theta_bfgs = np.zeros((n+1, 1))\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Графически оценим результаты вычислений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (theta_bfgs)\n",
    "yp = h(Xdata1, theta_bfgs) # Предсказанные значения\n",
    "plot_data(Xdata, ydata, Xdata, yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Упрощённая проверка моделей\n",
    "При помощи каждой из моделей предскажите рост 4-летнего ребёнка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ИСПРАВЬТЕ ИЛИ ДОПОЛНИТЕ КОД НИЖЕ\n",
    "y4_norm = 0\n",
    "y4_grad = 0\n",
    "y4_bfgs = 0\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. Цены на дом\n",
    "\n",
    "Требуется найти зависимость стоимости дома (в долларах США) от двух параметров: площади (в кв. футах, первый столбец) и количества спален (второй столбец).\n",
    "\n",
    "Загрузим исходные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat('prices.mat')\n",
    "Xdata = data['house']\n",
    "ydata = data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшие вычисления с помощью обоих рассмотренных методов выполните самостоятельно. В этой задаче регрессия множественная, но если вы в предыдущей задачи использовали векторизованные вычисления, то функции не потребуют значительного изменения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи каждой из моделей предскажите цену на дом площадью 2104 кв. фута с 3 спальнями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Сделайте выводы о применимости рассмотренных методов для решения задачи линейной регрессии.\n",
    "\n",
    "- Какие подготовительные действия приходится выполнять перед собственно обучением? Почему?\n",
    "- Какой из рассмотренных методов проще? Какой точнее?\n",
    "- Какие преимущества и недостатки у каждого и методов?\n",
    "- С какими сложностями вы столкнулись в ходе выполнения работы?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
